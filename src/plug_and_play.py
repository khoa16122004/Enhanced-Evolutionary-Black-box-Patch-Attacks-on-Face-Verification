from text_to_text_services import LlamaService
from get_architech import init_lvlm_model
from PIL import Image

# Kh·ªüi t·∫°o m√¥ h√¨nh
llm = LlamaService(model_name="Llama-7b")
lvlm_model, lvlm_image_token, _ = init_lvlm_model("llava-next-interleave-7b", "llava_qwen")

# T·∫£i ·∫£nh
img1 = Image.open("../lfw_dataset/lfw_original/Ziwang_Xu/Ziwang_Xu_0001.jpg").convert("RGB")
img2 = Image.open("../lfw_dataset/lfw_original/Ziwang_Xu/Ziwang_Xu_0001.jpg").convert("RGB")
img1.save("test1.png")
img2.save("test2.png")

# System prompt ƒë∆°n gi·∫£n h√≥a
llm_system_prompt = """You are analyzing facial features to verify if two people are the same.

TASK: Ask strategic questions about facial biometrics to determine if two images show the same person.


ASK ONE QUESTION PER TURN. If you have enough biometric info to decide, return: STOP

Next question:"""

# Thi·∫øt l·∫≠p ban ƒë·∫ßu
initial_question = "Describe the person's facial features in detail."
history = []
question = initial_question
max_rounds = 4

print("üîç FACE VERIFICATION GAME")
print("=" * 40)

for round_idx in range(max_rounds):
    # H·ªèi c·∫£ hai witness
    full_question = f"Focus on facial features only.\nQuestion: {question}\nImage: {lvlm_image_token}"
    
    answer_1 = lvlm_model.inference(full_question, [img1], num_return_sequences=1, 
                                  do_sample=True, temperature=0.7, reload=False)[0]
    answer_2 = lvlm_model.inference(full_question, [img2], num_return_sequences=1, 
                                  do_sample=True, temperature=0.7, reload=False)[0]

    # L∆∞u l·ªãch s·ª≠ ng·∫Øn g·ªçn
    history.append(f"Q: {question}\nA1: {answer_1}\nA2: {answer_2}")

    print(f"\nRound {round_idx + 1}:")
    print(f"‚ùì {question}")
    print(f"üë§ Image 1: {answer_1}")
    print(f"üë§ Image 2: {answer_2}")

    # T·∫°o context ng·∫Øn cho LLM
    context = "\n---\n".join(history)
    
    # H·ªèi c√¢u h·ªèi ti·∫øp theo
    next_question = llm.text_to_text(llm_system_prompt, f"History:\n{context}")[0].strip()
    
    print(f"ü§î Next: {next_question}")

    if "STOP" in next_question.upper():
        break

    question = next_question
    input("\nPress Enter for next round...")

# # K·∫øt lu·∫≠n cu·ªëi game - t·∫≠p trung v√†o biometrics
# final_prompt = f"""Based on facial biometric analysis:

# EVIDENCE:
# {chr(10).join(history)}

# INSTRUCTIONS:
# 1. Compare ONLY facial biometric features (eyes, nose, face shape, skin tone, etc.)
# 2. Ignore clothing, background, image quality
# 3. Give final verdict: SAME PERSON or DIFFERENT PEOPLE
# 4. List 3 key biometric evidence points
# 5. Rate confidence: HIGH/MEDIUM/LOW

# VERDICT:"""

# final_verdict = llm.text_to_text("", final_prompt)[0]

# print("\n" + "=" * 40)
# print("üèÜ FINAL ANALYSIS")
# print("=" * 40)
# print(final_verdict)
# print(f"\nüìä Rounds completed: {len(history)}")